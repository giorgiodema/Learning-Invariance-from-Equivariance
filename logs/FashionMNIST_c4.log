MODEL NAME:C4InvariantResNet_FashionMNIST
Using cache found in /home/giorgio/.cache/torch/hub/pytorch_vision_v0.10.0
/home/giorgio/.local/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
ResNet(
  (conv1): LiftingConvolution(
    (kernel): InterpolativeLiftingKernel(
      (group): CyclicGroup()
    )
  )
  (bn1): GroupBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): SpatialMaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn1): GroupBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn2): GroupBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn1): GroupBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn2): GroupBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn1): GroupBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn2): GroupBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): GroupConvolution(
          (kernel): InterpolativeGroupKernel(
            (group): CyclicGroup()
          )
        )
        (1): GroupBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn1): GroupBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn2): GroupBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn1): GroupBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn2): GroupBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): GroupConvolution(
          (kernel): InterpolativeGroupKernel(
            (group): CyclicGroup()
          )
        )
        (1): GroupBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn1): GroupBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn2): GroupBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn1): GroupBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn2): GroupBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): GroupConvolution(
          (kernel): InterpolativeGroupKernel(
            (group): CyclicGroup()
          )
        )
        (1): GroupBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn1): GroupBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): GroupConvolution(
        (kernel): InterpolativeGroupKernel(
          (group): CyclicGroup()
        )
      )
      (bn2): GroupBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): Sequential(
    (0): GroupAvgPool()
    (1): SpatialAvgPool()
  )
  (fc): Linear(in_features=256, out_features=10, bias=True)
)
N PARAMS: 11180842
ep:0/15    loss: 2.281770  [    0/54000]
ep:0/15    loss: 1.071234  [ 1600/54000]
ep:0/15    loss: 1.098500  [ 3200/54000]
ep:0/15    loss: 1.071371  [ 4800/54000]
ep:0/15    loss: 1.115019  [ 6400/54000]
ep:0/15    loss: 1.409233  [ 8000/54000]
ep:0/15    loss: 0.292080  [ 9600/54000]
ep:0/15    loss: 0.775366  [11200/54000]
ep:0/15    loss: 0.493054  [12800/54000]
ep:0/15    loss: 0.731275  [14400/54000]
ep:0/15    loss: 0.452318  [16000/54000]
ep:0/15    loss: 0.527661  [17600/54000]
ep:0/15    loss: 0.772594  [19200/54000]
ep:0/15    loss: 0.378880  [20800/54000]
ep:0/15    loss: 1.010048  [22400/54000]
ep:0/15    loss: 0.505880  [24000/54000]
ep:0/15    loss: 0.558695  [25600/54000]
ep:0/15    loss: 0.554424  [27200/54000]
ep:0/15    loss: 0.321742  [28800/54000]
ep:0/15    loss: 1.041538  [30400/54000]
ep:0/15    loss: 0.710018  [32000/54000]
ep:0/15    loss: 0.974474  [33600/54000]
ep:0/15    loss: 0.591387  [35200/54000]
ep:0/15    loss: 0.317044  [36800/54000]
ep:0/15    loss: 0.399267  [38400/54000]
ep:0/15    loss: 0.327329  [40000/54000]
ep:0/15    loss: 0.288072  [41600/54000]
ep:0/15    loss: 0.341635  [43200/54000]
ep:0/15    loss: 0.364678  [44800/54000]
ep:0/15    loss: 0.480929  [46400/54000]
ep:0/15    loss: 0.301834  [48000/54000]
ep:0/15    loss: 0.398436  [49600/54000]
ep:0/15    loss: 0.349482  [51200/54000]
ep:0/15    loss: 0.661162  [52800/54000]
-----------------------------
Val Acc:0.77  Val loss:0.596943    Train Acc:0.76
Loss decreased     inf->0.596943, Saving
ep:1/15    loss: 0.608941  [    0/54000]
ep:1/15    loss: 2.261634  [ 1600/54000]
ep:1/15    loss: 1.467993  [ 3200/54000]
ep:1/15    loss: 1.689970  [ 4800/54000]
ep:1/15    loss: 1.463972  [ 6400/54000]
ep:1/15    loss: 1.262963  [ 8000/54000]
ep:1/15    loss: 1.399713  [ 9600/54000]
ep:1/15    loss: 1.367727  [11200/54000]
ep:1/15    loss: 0.807786  [12800/54000]
ep:1/15    loss: 1.922515  [14400/54000]
ep:1/15    loss: 1.011473  [16000/54000]
ep:1/15    loss: 0.790597  [17600/54000]
ep:1/15    loss: 0.904646  [19200/54000]
ep:1/15    loss: 0.787255  [20800/54000]
ep:1/15    loss: 0.546629  [22400/54000]
ep:1/15    loss: 0.990353  [24000/54000]
ep:1/15    loss: 0.956103  [25600/54000]
ep:1/15    loss: 0.872140  [27200/54000]
ep:1/15    loss: 0.798178  [28800/54000]
ep:1/15    loss: 0.899751  [30400/54000]
ep:1/15    loss: 0.981414  [32000/54000]
ep:1/15    loss: 0.934558  [33600/54000]
ep:1/15    loss: 1.013836  [35200/54000]
ep:1/15    loss: 0.635742  [36800/54000]
ep:1/15    loss: 0.591353  [38400/54000]
ep:1/15    loss: 0.411563  [40000/54000]
ep:1/15    loss: 0.895363  [41600/54000]
ep:1/15    loss: 0.592857  [43200/54000]
ep:1/15    loss: 0.747422  [44800/54000]
ep:1/15    loss: 0.558317  [46400/54000]
ep:1/15    loss: 0.597876  [48000/54000]
ep:1/15    loss: 0.393673  [49600/54000]
ep:1/15    loss: 1.110271  [51200/54000]
ep:1/15    loss: 0.521458  [52800/54000]
-----------------------------
Val Acc:0.79  Val loss:0.559914    Train Acc:0.62
Loss decreased 0.596943->0.559914, Saving
ep:2/15    loss: 1.025096  [    0/54000]
ep:2/15    loss: 0.486398  [ 1600/54000]
ep:2/15    loss: 0.630641  [ 3200/54000]
ep:2/15    loss: 1.207033  [ 4800/54000]
ep:2/15    loss: 0.695922  [ 6400/54000]
ep:2/15    loss: 0.794848  [ 8000/54000]
ep:2/15    loss: 0.385327  [ 9600/54000]
ep:2/15    loss: 0.698895  [11200/54000]
ep:2/15    loss: 0.437736  [12800/54000]
ep:2/15    loss: 0.679830  [14400/54000]
ep:2/15    loss: 0.810668  [16000/54000]
ep:2/15    loss: 0.284754  [17600/54000]
ep:2/15    loss: 0.350280  [19200/54000]
ep:2/15    loss: 0.712120  [20800/54000]
ep:2/15    loss: 0.445346  [22400/54000]
ep:2/15    loss: 0.326549  [24000/54000]
ep:2/15    loss: 0.323454  [25600/54000]
ep:2/15    loss: 0.716408  [27200/54000]
ep:2/15    loss: 0.210583  [28800/54000]
ep:2/15    loss: 0.428827  [30400/54000]
ep:2/15    loss: 0.335573  [32000/54000]
ep:2/15    loss: 0.164659  [33600/54000]
ep:2/15    loss: 0.256450  [35200/54000]
ep:2/15    loss: 0.390747  [36800/54000]
ep:2/15    loss: 0.414194  [38400/54000]
ep:2/15    loss: 0.823056  [40000/54000]
ep:2/15    loss: 0.536104  [41600/54000]
ep:2/15    loss: 0.387286  [43200/54000]
ep:2/15    loss: 0.282378  [44800/54000]
ep:2/15    loss: 0.668979  [46400/54000]
ep:2/15    loss: 0.486205  [48000/54000]
ep:2/15    loss: 0.261389  [49600/54000]
ep:2/15    loss: 1.179605  [51200/54000]
ep:2/15    loss: 0.629168  [52800/54000]
-----------------------------
Val Acc:0.84  Val loss:0.407186    Train Acc:0.82
Loss decreased 0.559914->0.407186, Saving
ep:3/15    loss: 0.582408  [    0/54000]
ep:3/15    loss: 0.193043  [ 1600/54000]
ep:3/15    loss: 0.287144  [ 3200/54000]
ep:3/15    loss: 0.583224  [ 4800/54000]
ep:3/15    loss: 0.168721  [ 6400/54000]
ep:3/15    loss: 0.537133  [ 8000/54000]
ep:3/15    loss: 0.335496  [ 9600/54000]
ep:3/15    loss: 0.622615  [11200/54000]
ep:3/15    loss: 0.456539  [12800/54000]
ep:3/15    loss: 0.019269  [14400/54000]
ep:3/15    loss: 0.503914  [16000/54000]
ep:3/15    loss: 0.768832  [17600/54000]
ep:3/15    loss: 0.137558  [19200/54000]
ep:3/15    loss: 0.398181  [20800/54000]
ep:3/15    loss: 0.651045  [22400/54000]
ep:3/15    loss: 0.239548  [24000/54000]
ep:3/15    loss: 0.352804  [25600/54000]
ep:3/15    loss: 0.434733  [27200/54000]
ep:3/15    loss: 0.172516  [28800/54000]
ep:3/15    loss: 0.205577  [30400/54000]
ep:3/15    loss: 0.357037  [32000/54000]
ep:3/15    loss: 0.063509  [33600/54000]
ep:3/15    loss: 0.332189  [35200/54000]
ep:3/15    loss: 0.271550  [36800/54000]
ep:3/15    loss: 0.842157  [38400/54000]
ep:3/15    loss: 1.400966  [40000/54000]
ep:3/15    loss: 0.411712  [41600/54000]
ep:3/15    loss: 0.512902  [43200/54000]
ep:3/15    loss: 0.325156  [44800/54000]
ep:3/15    loss: 0.551591  [46400/54000]
ep:3/15    loss: 0.249769  [48000/54000]
ep:3/15    loss: 0.204389  [49600/54000]
ep:3/15    loss: 0.451505  [51200/54000]
ep:3/15    loss: 0.109426  [52800/54000]
-----------------------------
Val Acc:0.85  Val loss:0.384667    Train Acc:0.86
Loss decreased 0.407186->0.384667, Saving
ep:4/15    loss: 0.415521  [    0/54000]
ep:4/15    loss: 0.532837  [ 1600/54000]
ep:4/15    loss: 0.379262  [ 3200/54000]
ep:4/15    loss: 0.148126  [ 4800/54000]
ep:4/15    loss: 0.650977  [ 6400/54000]
ep:4/15    loss: 0.062066  [ 8000/54000]
ep:4/15    loss: 0.201935  [ 9600/54000]
ep:4/15    loss: 0.198099  [11200/54000]
ep:4/15    loss: 0.185850  [12800/54000]
ep:4/15    loss: 0.303060  [14400/54000]
ep:4/15    loss: 0.167904  [16000/54000]
ep:4/15    loss: 0.356951  [17600/54000]
ep:4/15    loss: 0.131657  [19200/54000]
ep:4/15    loss: 0.105936  [20800/54000]
ep:4/15    loss: 0.276982  [22400/54000]
ep:4/15    loss: 0.255014  [24000/54000]
ep:4/15    loss: 0.353856  [25600/54000]
ep:4/15    loss: 0.167569  [27200/54000]
ep:4/15    loss: 0.183897  [28800/54000]
ep:4/15    loss: 0.196352  [30400/54000]
ep:4/15    loss: 0.483515  [32000/54000]
ep:4/15    loss: 0.671766  [33600/54000]
ep:4/15    loss: 0.165211  [35200/54000]
ep:4/15    loss: 0.319597  [36800/54000]
ep:4/15    loss: 0.524488  [38400/54000]
ep:4/15    loss: 0.480747  [40000/54000]
ep:4/15    loss: 0.030715  [41600/54000]
ep:4/15    loss: 0.202909  [43200/54000]
ep:4/15    loss: 0.476779  [44800/54000]
ep:4/15    loss: 0.421722  [46400/54000]
ep:4/15    loss: 0.227262  [48000/54000]
ep:4/15    loss: 0.183558  [49600/54000]
ep:4/15    loss: 0.066917  [51200/54000]
ep:4/15    loss: 0.923654  [52800/54000]
-----------------------------
Val Acc:0.89  Val loss:0.305174    Train Acc:0.88
Loss decreased 0.384667->0.305174, Saving
ep:5/15    loss: 0.728246  [    0/54000]
ep:5/15    loss: 0.163900  [ 1600/54000]
ep:5/15    loss: 0.294403  [ 3200/54000]
ep:5/15    loss: 0.318334  [ 4800/54000]
ep:5/15    loss: 0.140880  [ 6400/54000]
ep:5/15    loss: 0.194417  [ 8000/54000]
ep:5/15    loss: 0.383314  [ 9600/54000]
ep:5/15    loss: 0.045244  [11200/54000]
ep:5/15    loss: 0.311046  [12800/54000]
ep:5/15    loss: 0.570029  [14400/54000]
ep:5/15    loss: 0.224301  [16000/54000]
ep:5/15    loss: 0.213376  [17600/54000]
ep:5/15    loss: 0.234941  [19200/54000]
ep:5/15    loss: 0.385902  [20800/54000]
ep:5/15    loss: 0.568018  [22400/54000]
ep:5/15    loss: 0.276744  [24000/54000]
ep:5/15    loss: 0.522570  [25600/54000]
ep:5/15    loss: 0.111392  [27200/54000]
ep:5/15    loss: 0.149734  [28800/54000]
ep:5/15    loss: 0.219491  [30400/54000]
ep:5/15    loss: 0.562517  [32000/54000]
ep:5/15    loss: 0.370452  [33600/54000]
ep:5/15    loss: 0.248911  [35200/54000]
ep:5/15    loss: 0.180518  [36800/54000]
ep:5/15    loss: 0.121095  [38400/54000]
ep:5/15    loss: 0.353041  [40000/54000]
ep:5/15    loss: 0.219857  [41600/54000]
ep:5/15    loss: 0.235357  [43200/54000]
ep:5/15    loss: 0.343145  [44800/54000]
ep:5/15    loss: 0.461786  [46400/54000]
ep:5/15    loss: 0.048049  [48000/54000]
ep:5/15    loss: 0.025322  [49600/54000]
ep:5/15    loss: 0.265862  [51200/54000]
ep:5/15    loss: 0.231110  [52800/54000]
-----------------------------
Val Acc:0.88  Val loss:0.316633    Train Acc:0.89
ep:6/15    loss: 0.446046  [    0/54000]
ep:6/15    loss: 0.019339  [ 1600/54000]
ep:6/15    loss: 0.026340  [ 3200/54000]
ep:6/15    loss: 0.354565  [ 4800/54000]
ep:6/15    loss: 0.205062  [ 6400/54000]
ep:6/15    loss: 0.110740  [ 8000/54000]
ep:6/15    loss: 0.245559  [ 9600/54000]
ep:6/15    loss: 0.298265  [11200/54000]
ep:6/15    loss: 0.385341  [12800/54000]
ep:6/15    loss: 0.259025  [14400/54000]
ep:6/15    loss: 0.754508  [16000/54000]
ep:6/15    loss: 0.071278  [17600/54000]
ep:6/15    loss: 0.325458  [19200/54000]
ep:6/15    loss: 0.069524  [20800/54000]
ep:6/15    loss: 0.236757  [22400/54000]
ep:6/15    loss: 0.226567  [24000/54000]
ep:6/15    loss: 0.760128  [25600/54000]
ep:6/15    loss: 0.142721  [27200/54000]
ep:6/15    loss: 0.080613  [28800/54000]
ep:6/15    loss: 0.007258  [30400/54000]
ep:6/15    loss: 0.024161  [32000/54000]
ep:6/15    loss: 0.048589  [33600/54000]
ep:6/15    loss: 0.377791  [35200/54000]
ep:6/15    loss: 0.117058  [36800/54000]
ep:6/15    loss: 0.236551  [38400/54000]
ep:6/15    loss: 0.471274  [40000/54000]
ep:6/15    loss: 0.352474  [41600/54000]
ep:6/15    loss: 0.136055  [43200/54000]
ep:6/15    loss: 0.431099  [44800/54000]
ep:6/15    loss: 0.304903  [46400/54000]
ep:6/15    loss: 0.331620  [48000/54000]
ep:6/15    loss: 0.937510  [49600/54000]
ep:6/15    loss: 0.283509  [51200/54000]
ep:6/15    loss: 0.614883  [52800/54000]
-----------------------------
Val Acc:0.92  Val loss:0.253889    Train Acc:0.90
Loss decreased 0.305174->0.253889, Saving
ep:7/15    loss: 0.272353  [    0/54000]
ep:7/15    loss: 0.230743  [ 1600/54000]
ep:7/15    loss: 0.160406  [ 3200/54000]
ep:7/15    loss: 0.133646  [ 4800/54000]
ep:7/15    loss: 0.126304  [ 6400/54000]
ep:7/15    loss: 0.068574  [ 8000/54000]
ep:7/15    loss: 0.047658  [ 9600/54000]
ep:7/15    loss: 0.153706  [11200/54000]
ep:7/15    loss: 0.183266  [12800/54000]
ep:7/15    loss: 0.199112  [14400/54000]
ep:7/15    loss: 0.263319  [16000/54000]
ep:7/15    loss: 0.118389  [17600/54000]
ep:7/15    loss: 0.383598  [19200/54000]
ep:7/15    loss: 0.023097  [20800/54000]
ep:7/15    loss: 0.277092  [22400/54000]
ep:7/15    loss: 0.093496  [24000/54000]
ep:7/15    loss: 0.275219  [25600/54000]
ep:7/15    loss: 0.254845  [27200/54000]
ep:7/15    loss: 0.238685  [28800/54000]
ep:7/15    loss: 0.104764  [30400/54000]
ep:7/15    loss: 0.361314  [32000/54000]
ep:7/15    loss: 0.090247  [33600/54000]
ep:7/15    loss: 0.203617  [35200/54000]
ep:7/15    loss: 0.780242  [36800/54000]
ep:7/15    loss: 0.333138  [38400/54000]
ep:7/15    loss: 0.321645  [40000/54000]
ep:7/15    loss: 0.122595  [41600/54000]
ep:7/15    loss: 0.109360  [43200/54000]
ep:7/15    loss: 0.280009  [44800/54000]
ep:7/15    loss: 0.336601  [46400/54000]
ep:7/15    loss: 0.074089  [48000/54000]
ep:7/15    loss: 0.331120  [49600/54000]
ep:7/15    loss: 0.052039  [51200/54000]
ep:7/15    loss: 0.409715  [52800/54000]
-----------------------------
Val Acc:0.93  Val loss:0.213323    Train Acc:0.92
Loss decreased 0.253889->0.213323, Saving
ep:8/15    loss: 0.469216  [    0/54000]
ep:8/15    loss: 0.045545  [ 1600/54000]
ep:8/15    loss: 0.111865  [ 3200/54000]
ep:8/15    loss: 0.245911  [ 4800/54000]
ep:8/15    loss: 0.550664  [ 6400/54000]
ep:8/15    loss: 0.167138  [ 8000/54000]
ep:8/15    loss: 0.281943  [ 9600/54000]
ep:8/15    loss: 0.138312  [11200/54000]
ep:8/15    loss: 0.031142  [12800/54000]
ep:8/15    loss: 0.077563  [14400/54000]
ep:8/15    loss: 0.394971  [16000/54000]
ep:8/15    loss: 0.183956  [17600/54000]
ep:8/15    loss: 0.019293  [19200/54000]
ep:8/15    loss: 0.496780  [20800/54000]
ep:8/15    loss: 0.163644  [22400/54000]
ep:8/15    loss: 0.300871  [24000/54000]
ep:8/15    loss: 0.188165  [25600/54000]
ep:8/15    loss: 0.209713  [27200/54000]
ep:8/15    loss: 0.423392  [28800/54000]
ep:8/15    loss: 0.173967  [30400/54000]
ep:8/15    loss: 0.410894  [32000/54000]
ep:8/15    loss: 0.106416  [33600/54000]
ep:8/15    loss: 0.001137  [35200/54000]
ep:8/15    loss: 0.125526  [36800/54000]
ep:8/15    loss: 0.198749  [38400/54000]
ep:8/15    loss: 0.163209  [40000/54000]
ep:8/15    loss: 0.168250  [41600/54000]
ep:8/15    loss: 0.242619  [43200/54000]
ep:8/15    loss: 0.176292  [44800/54000]
ep:8/15    loss: 0.079404  [46400/54000]
ep:8/15    loss: 0.271835  [48000/54000]
ep:8/15    loss: 0.362355  [49600/54000]
ep:8/15    loss: 0.064446  [51200/54000]
ep:8/15    loss: 0.158607  [52800/54000]
-----------------------------
Val Acc:0.93  Val loss:0.182565    Train Acc:0.92
Loss decreased 0.213323->0.182565, Saving
ep:9/15    loss: 0.043143  [    0/54000]
ep:9/15    loss: 0.520470  [ 1600/54000]
ep:9/15    loss: 0.186864  [ 3200/54000]
ep:9/15    loss: 0.231188  [ 4800/54000]
ep:9/15    loss: 0.111709  [ 6400/54000]
ep:9/15    loss: 0.226235  [ 8000/54000]
ep:9/15    loss: 0.102304  [ 9600/54000]
ep:9/15    loss: 0.076982  [11200/54000]
ep:9/15    loss: 0.237894  [12800/54000]
ep:9/15    loss: 0.073770  [14400/54000]
ep:9/15    loss: 0.120178  [16000/54000]
ep:9/15    loss: 0.130651  [17600/54000]
ep:9/15    loss: 0.003871  [19200/54000]
ep:9/15    loss: 0.020795  [20800/54000]
ep:9/15    loss: 0.151161  [22400/54000]
ep:9/15    loss: 0.128787  [24000/54000]
ep:9/15    loss: 0.150557  [25600/54000]
ep:9/15    loss: 0.070575  [27200/54000]
ep:9/15    loss: 0.062507  [28800/54000]
ep:9/15    loss: 0.040855  [30400/54000]
ep:9/15    loss: 0.113575  [32000/54000]
ep:9/15    loss: 0.047579  [33600/54000]
ep:9/15    loss: 0.024309  [35200/54000]
ep:9/15    loss: 0.064986  [36800/54000]
ep:9/15    loss: 0.241940  [38400/54000]
ep:9/15    loss: 0.112389  [40000/54000]
ep:9/15    loss: 0.252870  [41600/54000]
ep:9/15    loss: 0.316765  [43200/54000]
ep:9/15    loss: 0.600224  [44800/54000]
ep:9/15    loss: 0.036767  [46400/54000]
ep:9/15    loss: 0.112591  [48000/54000]
ep:9/15    loss: 0.057698  [49600/54000]
ep:9/15    loss: 0.243517  [51200/54000]
ep:9/15    loss: 0.433569  [52800/54000]
-----------------------------
Val Acc:0.94  Val loss:0.179462    Train Acc:0.93
Loss decreased 0.182565->0.179462, Saving
ep:10/15    loss: 0.359376  [    0/54000]
ep:10/15    loss: 0.020273  [ 1600/54000]
ep:10/15    loss: 0.041213  [ 3200/54000]
ep:10/15    loss: 0.032542  [ 4800/54000]
ep:10/15    loss: 0.292735  [ 6400/54000]
ep:10/15    loss: 0.433958  [ 8000/54000]
ep:10/15    loss: 0.468612  [ 9600/54000]
ep:10/15    loss: 0.568084  [11200/54000]
ep:10/15    loss: 0.018563  [12800/54000]
ep:10/15    loss: 0.255229  [14400/54000]
ep:10/15    loss: 0.247697  [16000/54000]
ep:10/15    loss: 0.032407  [17600/54000]
ep:10/15    loss: 0.369929  [19200/54000]
ep:10/15    loss: 0.065694  [20800/54000]
ep:10/15    loss: 0.110064  [22400/54000]
ep:10/15    loss: 0.143190  [24000/54000]
ep:10/15    loss: 0.320557  [25600/54000]
ep:10/15    loss: 0.213389  [27200/54000]
ep:10/15    loss: 0.091378  [28800/54000]
ep:10/15    loss: 0.000924  [30400/54000]
ep:10/15    loss: 0.056695  [32000/54000]
ep:10/15    loss: 0.018879  [33600/54000]
ep:10/15    loss: 0.341474  [35200/54000]
ep:10/15    loss: 0.056440  [36800/54000]
ep:10/15    loss: 0.159725  [38400/54000]
ep:10/15    loss: 0.098484  [40000/54000]
ep:10/15    loss: 0.087808  [41600/54000]
ep:10/15    loss: 0.097136  [43200/54000]
ep:10/15    loss: 0.009756  [44800/54000]
ep:10/15    loss: 0.327850  [46400/54000]
ep:10/15    loss: 0.179126  [48000/54000]
ep:10/15    loss: 0.010217  [49600/54000]
ep:10/15    loss: 0.052873  [51200/54000]
ep:10/15    loss: 0.288746  [52800/54000]
-----------------------------
Val Acc:0.94  Val loss:0.166220    Train Acc:0.94
Loss decreased 0.179462->0.166220, Saving
ep:11/15    loss: 0.060233  [    0/54000]
ep:11/15    loss: 0.002852  [ 1600/54000]
ep:11/15    loss: 0.079060  [ 3200/54000]
ep:11/15    loss: 0.187855  [ 4800/54000]
ep:11/15    loss: 0.026467  [ 6400/54000]
ep:11/15    loss: 0.284556  [ 8000/54000]
ep:11/15    loss: 0.522141  [ 9600/54000]
ep:11/15    loss: 0.011079  [11200/54000]
ep:11/15    loss: 0.009852  [12800/54000]
ep:11/15    loss: 0.421411  [14400/54000]
ep:11/15    loss: 0.140811  [16000/54000]
ep:11/15    loss: 0.119984  [17600/54000]
ep:11/15    loss: 0.209164  [19200/54000]
ep:11/15    loss: 0.237916  [20800/54000]
ep:11/15    loss: 0.174932  [22400/54000]
ep:11/15    loss: 0.108800  [24000/54000]
ep:11/15    loss: 0.009614  [25600/54000]
ep:11/15    loss: 0.348874  [27200/54000]
ep:11/15    loss: 0.203015  [28800/54000]
ep:11/15    loss: 0.247576  [30400/54000]
ep:11/15    loss: 0.303655  [32000/54000]
ep:11/15    loss: 0.256600  [33600/54000]
ep:11/15    loss: 0.253205  [35200/54000]
ep:11/15    loss: 0.190897  [36800/54000]
ep:11/15    loss: 0.103721  [38400/54000]
ep:11/15    loss: 0.055780  [40000/54000]
ep:11/15    loss: 0.180676  [41600/54000]
ep:11/15    loss: 0.224542  [43200/54000]
ep:11/15    loss: 0.053466  [44800/54000]
ep:11/15    loss: 0.007146  [46400/54000]
ep:11/15    loss: 0.196511  [48000/54000]
ep:11/15    loss: 0.275606  [49600/54000]
ep:11/15    loss: 0.368938  [51200/54000]
ep:11/15    loss: 0.257847  [52800/54000]
-----------------------------
Val Acc:0.96  Val loss:0.121198    Train Acc:0.95
Loss decreased 0.166220->0.121198, Saving
ep:12/15    loss: 0.189102  [    0/54000]
ep:12/15    loss: 0.258242  [ 1600/54000]
ep:12/15    loss: 0.150210  [ 3200/54000]
ep:12/15    loss: 0.308388  [ 4800/54000]
ep:12/15    loss: 0.316242  [ 6400/54000]
ep:12/15    loss: 0.011416  [ 8000/54000]
ep:12/15    loss: 0.065713  [ 9600/54000]
ep:12/15    loss: 0.099013  [11200/54000]
ep:12/15    loss: 0.171299  [12800/54000]
ep:12/15    loss: 0.013804  [14400/54000]
ep:12/15    loss: 0.072181  [16000/54000]
ep:12/15    loss: 0.384802  [17600/54000]
ep:12/15    loss: 0.053500  [19200/54000]
ep:12/15    loss: 0.088874  [20800/54000]
ep:12/15    loss: 0.062292  [22400/54000]
ep:12/15    loss: 0.007087  [24000/54000]
ep:12/15    loss: 0.127905  [25600/54000]
ep:12/15    loss: 0.179970  [27200/54000]
ep:12/15    loss: 0.203834  [28800/54000]
ep:12/15    loss: 0.206286  [30400/54000]
ep:12/15    loss: 0.160186  [32000/54000]
ep:12/15    loss: 0.034682  [33600/54000]
ep:12/15    loss: 0.016998  [35200/54000]
ep:12/15    loss: 0.095109  [36800/54000]
ep:12/15    loss: 0.064643  [38400/54000]
ep:12/15    loss: 0.252416  [40000/54000]
ep:12/15    loss: 0.022509  [41600/54000]
ep:12/15    loss: 0.129422  [43200/54000]
ep:12/15    loss: 0.035877  [44800/54000]
ep:12/15    loss: 0.212096  [46400/54000]
ep:12/15    loss: 0.239061  [48000/54000]
ep:12/15    loss: 0.008590  [49600/54000]
ep:12/15    loss: 0.025375  [51200/54000]
ep:12/15    loss: 0.074525  [52800/54000]
-----------------------------
Val Acc:0.96  Val loss:0.113024    Train Acc:0.96
Loss decreased 0.121198->0.113024, Saving
ep:13/15    loss: 0.005934  [    0/54000]
ep:13/15    loss: 0.030142  [ 1600/54000]
ep:13/15    loss: 0.002568  [ 3200/54000]
ep:13/15    loss: 0.073396  [ 4800/54000]
ep:13/15    loss: 0.009723  [ 6400/54000]
ep:13/15    loss: 0.014330  [ 8000/54000]
ep:13/15    loss: 0.139942  [ 9600/54000]
ep:13/15    loss: 0.213417  [11200/54000]
ep:13/15    loss: 0.003361  [12800/54000]
ep:13/15    loss: 0.010462  [14400/54000]
ep:13/15    loss: 0.010341  [16000/54000]
ep:13/15    loss: 0.298460  [17600/54000]
ep:13/15    loss: 0.000484  [19200/54000]
ep:13/15    loss: 0.165850  [20800/54000]
ep:13/15    loss: 0.017906  [22400/54000]
ep:13/15    loss: 0.006701  [24000/54000]
ep:13/15    loss: 0.008211  [25600/54000]
ep:13/15    loss: 0.010812  [27200/54000]
ep:13/15    loss: 0.266540  [28800/54000]
ep:13/15    loss: 0.014787  [30400/54000]
ep:13/15    loss: 0.275973  [32000/54000]
ep:13/15    loss: 0.015840  [33600/54000]
ep:13/15    loss: 0.064423  [35200/54000]
ep:13/15    loss: 0.082286  [36800/54000]
ep:13/15    loss: 0.016677  [38400/54000]
ep:13/15    loss: 0.046238  [40000/54000]
ep:13/15    loss: 0.033965  [41600/54000]
ep:13/15    loss: 0.151537  [43200/54000]
ep:13/15    loss: 0.182575  [44800/54000]
ep:13/15    loss: 0.152798  [46400/54000]
ep:13/15    loss: 0.009342  [48000/54000]
ep:13/15    loss: 0.064376  [49600/54000]
ep:13/15    loss: 0.031916  [51200/54000]
ep:13/15    loss: 0.097049  [52800/54000]
-----------------------------
Val Acc:0.97  Val loss:0.089217    Train Acc:0.97
Loss decreased 0.113024->0.089217, Saving
ep:14/15    loss: 0.002981  [    0/54000]
ep:14/15    loss: 0.191544  [ 1600/54000]
ep:14/15    loss: 0.042637  [ 3200/54000]
ep:14/15    loss: 0.013643  [ 4800/54000]
ep:14/15    loss: 0.021882  [ 6400/54000]
ep:14/15    loss: 0.048261  [ 8000/54000]
ep:14/15    loss: 0.015725  [ 9600/54000]
ep:14/15    loss: 0.136583  [11200/54000]
ep:14/15    loss: 0.023794  [12800/54000]
ep:14/15    loss: 0.162705  [14400/54000]
ep:14/15    loss: 0.001215  [16000/54000]
ep:14/15    loss: 0.035386  [17600/54000]
ep:14/15    loss: 0.015005  [19200/54000]
ep:14/15    loss: 0.012796  [20800/54000]
ep:14/15    loss: 0.002426  [22400/54000]
ep:14/15    loss: 0.030473  [24000/54000]
ep:14/15    loss: 0.017716  [25600/54000]
ep:14/15    loss: 0.070888  [27200/54000]
ep:14/15    loss: 0.005955  [28800/54000]
ep:14/15    loss: 0.099252  [30400/54000]
ep:14/15    loss: 0.044655  [32000/54000]
ep:14/15    loss: 0.390854  [33600/54000]
ep:14/15    loss: 0.045383  [35200/54000]
ep:14/15    loss: 0.009371  [36800/54000]
ep:14/15    loss: 0.071185  [38400/54000]
ep:14/15    loss: 0.019456  [40000/54000]
ep:14/15    loss: 0.012775  [41600/54000]
ep:14/15    loss: 0.009072  [43200/54000]
ep:14/15    loss: 0.024173  [44800/54000]
ep:14/15    loss: 0.003628  [46400/54000]
ep:14/15    loss: 0.099303  [48000/54000]
ep:14/15    loss: 0.329072  [49600/54000]
ep:14/15    loss: 0.023338  [51200/54000]
ep:14/15    loss: 0.019808  [52800/54000]
-----------------------------
Val Acc:0.98  Val loss:0.073639    Train Acc:0.97
Loss decreased 0.089217->0.073639, Saving
