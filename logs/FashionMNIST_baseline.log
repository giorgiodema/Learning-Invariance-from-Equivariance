MODEL NAME:ResNet18_FashionMNIST
ResNet(
  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=10, bias=True)
)
N PARAMS: 11175370
ep:0/15    loss: 2.458308  [    0/54000]
ep:0/15    loss: 0.664474  [ 3200/54000]
ep:0/15    loss: 0.799440  [ 6400/54000]
ep:0/15    loss: 0.518325  [ 9600/54000]
ep:0/15    loss: 0.369158  [12800/54000]
ep:0/15    loss: 0.583791  [16000/54000]
ep:0/15    loss: 0.272468  [19200/54000]
ep:0/15    loss: 0.206578  [22400/54000]
ep:0/15    loss: 0.416512  [25600/54000]
ep:0/15    loss: 0.148789  [28800/54000]
ep:0/15    loss: 0.477970  [32000/54000]
ep:0/15    loss: 0.391867  [35200/54000]
ep:0/15    loss: 0.307712  [38400/54000]
ep:0/15    loss: 0.402420  [41600/54000]
ep:0/15    loss: 0.210254  [44800/54000]
ep:0/15    loss: 0.460960  [48000/54000]
ep:0/15    loss: 0.381416  [51200/54000]
-----------------------------
Val Acc:0.90  Val loss:0.283113    Train Acc:0.84
Loss decreased     inf->0.283113, Saving
ep:1/15    loss: 0.395973  [    0/54000]
ep:1/15    loss: 0.328242  [ 3200/54000]
ep:1/15    loss: 0.302957  [ 6400/54000]
ep:1/15    loss: 0.437308  [ 9600/54000]
ep:1/15    loss: 0.252289  [12800/54000]
ep:1/15    loss: 0.349514  [16000/54000]
ep:1/15    loss: 0.414558  [19200/54000]
ep:1/15    loss: 0.384622  [22400/54000]
ep:1/15    loss: 0.376614  [25600/54000]
ep:1/15    loss: 0.529825  [28800/54000]
ep:1/15    loss: 0.195397  [32000/54000]
ep:1/15    loss: 0.191101  [35200/54000]
ep:1/15    loss: 0.223984  [38400/54000]
ep:1/15    loss: 0.149678  [41600/54000]
ep:1/15    loss: 0.143112  [44800/54000]
ep:1/15    loss: 0.094274  [48000/54000]
ep:1/15    loss: 0.177051  [51200/54000]
-----------------------------
Val Acc:0.91  Val loss:0.241221    Train Acc:0.87
Loss decreased 0.283113->0.241221, Saving
ep:2/15    loss: 0.329213  [    0/54000]
ep:2/15    loss: 0.533774  [ 3200/54000]
ep:2/15    loss: 0.248968  [ 6400/54000]
ep:2/15    loss: 0.306294  [ 9600/54000]
ep:2/15    loss: 0.059087  [12800/54000]
ep:2/15    loss: 0.449061  [16000/54000]
ep:2/15    loss: 0.167970  [19200/54000]
ep:2/15    loss: 0.279472  [22400/54000]
ep:2/15    loss: 0.408443  [25600/54000]
ep:2/15    loss: 0.158039  [28800/54000]
ep:2/15    loss: 0.127682  [32000/54000]
ep:2/15    loss: 0.313278  [35200/54000]
ep:2/15    loss: 0.305655  [38400/54000]
ep:2/15    loss: 0.217629  [41600/54000]
ep:2/15    loss: 0.384043  [44800/54000]
ep:2/15    loss: 0.198539  [48000/54000]
ep:2/15    loss: 0.135684  [51200/54000]
-----------------------------
Val Acc:0.92  Val loss:0.211156    Train Acc:0.91
Loss decreased 0.241221->0.211156, Saving
ep:3/15    loss: 0.179611  [    0/54000]
ep:3/15    loss: 0.248832  [ 3200/54000]
ep:3/15    loss: 0.086738  [ 6400/54000]
ep:3/15    loss: 0.314792  [ 9600/54000]
ep:3/15    loss: 0.187948  [12800/54000]
ep:3/15    loss: 0.231148  [16000/54000]
ep:3/15    loss: 0.226798  [19200/54000]
ep:3/15    loss: 0.278773  [22400/54000]
ep:3/15    loss: 0.227085  [25600/54000]
ep:3/15    loss: 0.217934  [28800/54000]
ep:3/15    loss: 0.262291  [32000/54000]
ep:3/15    loss: 0.250344  [35200/54000]
ep:3/15    loss: 0.342371  [38400/54000]
ep:3/15    loss: 0.146092  [41600/54000]
ep:3/15    loss: 0.231898  [44800/54000]
ep:3/15    loss: 0.460356  [48000/54000]
ep:3/15    loss: 0.186426  [51200/54000]
-----------------------------
Val Acc:0.94  Val loss:0.185400    Train Acc:0.92
Loss decreased 0.211156->0.185400, Saving
ep:4/15    loss: 0.161422  [    0/54000]
ep:4/15    loss: 0.106659  [ 3200/54000]
ep:4/15    loss: 0.324144  [ 6400/54000]
ep:4/15    loss: 0.168946  [ 9600/54000]
ep:4/15    loss: 0.222290  [12800/54000]
ep:4/15    loss: 0.090329  [16000/54000]
ep:4/15    loss: 0.183255  [19200/54000]
ep:4/15    loss: 0.199199  [22400/54000]
ep:4/15    loss: 0.222624  [25600/54000]
ep:4/15    loss: 0.150654  [28800/54000]
ep:4/15    loss: 0.264168  [32000/54000]
ep:4/15    loss: 0.130621  [35200/54000]
ep:4/15    loss: 0.236496  [38400/54000]
ep:4/15    loss: 0.124396  [41600/54000]
ep:4/15    loss: 0.062135  [44800/54000]
ep:4/15    loss: 0.069440  [48000/54000]
ep:4/15    loss: 0.104534  [51200/54000]
-----------------------------
Val Acc:0.94  Val loss:0.153719    Train Acc:0.93
Loss decreased 0.185400->0.153719, Saving
ep:5/15    loss: 0.191998  [    0/54000]
ep:5/15    loss: 0.203483  [ 3200/54000]
ep:5/15    loss: 0.065624  [ 6400/54000]
ep:5/15    loss: 0.120069  [ 9600/54000]
ep:5/15    loss: 0.131217  [12800/54000]
ep:5/15    loss: 0.162669  [16000/54000]
ep:5/15    loss: 0.285510  [19200/54000]
ep:5/15    loss: 0.368326  [22400/54000]
ep:5/15    loss: 0.089086  [25600/54000]
ep:5/15    loss: 0.122797  [28800/54000]
ep:5/15    loss: 0.119664  [32000/54000]
ep:5/15    loss: 0.035718  [35200/54000]
ep:5/15    loss: 0.181406  [38400/54000]
ep:5/15    loss: 0.155186  [41600/54000]
ep:5/15    loss: 0.038856  [44800/54000]
ep:5/15    loss: 0.184756  [48000/54000]
ep:5/15    loss: 0.243139  [51200/54000]
-----------------------------
Val Acc:0.95  Val loss:0.131264    Train Acc:0.95
Loss decreased 0.153719->0.131264, Saving
ep:6/15    loss: 0.040568  [    0/54000]
ep:6/15    loss: 0.094910  [ 3200/54000]
ep:6/15    loss: 0.038246  [ 6400/54000]
ep:6/15    loss: 0.086545  [ 9600/54000]
ep:6/15    loss: 0.034578  [12800/54000]
ep:6/15    loss: 0.070209  [16000/54000]
ep:6/15    loss: 0.125509  [19200/54000]
ep:6/15    loss: 0.099996  [22400/54000]
ep:6/15    loss: 0.181744  [25600/54000]
ep:6/15    loss: 0.164676  [28800/54000]
ep:6/15    loss: 0.114961  [32000/54000]
ep:6/15    loss: 0.212810  [35200/54000]
ep:6/15    loss: 0.042835  [38400/54000]
ep:6/15    loss: 0.036298  [41600/54000]
ep:6/15    loss: 0.098561  [44800/54000]
ep:6/15    loss: 0.211654  [48000/54000]
ep:6/15    loss: 0.036010  [51200/54000]
-----------------------------
Val Acc:0.97  Val loss:0.093364    Train Acc:0.96
Loss decreased 0.131264->0.093364, Saving
ep:7/15    loss: 0.081322  [    0/54000]
ep:7/15    loss: 0.089813  [ 3200/54000]
ep:7/15    loss: 0.366601  [ 6400/54000]
ep:7/15    loss: 0.112901  [ 9600/54000]
ep:7/15    loss: 0.051068  [12800/54000]
ep:7/15    loss: 0.154058  [16000/54000]
ep:7/15    loss: 0.101287  [19200/54000]
ep:7/15    loss: 0.123983  [22400/54000]
ep:7/15    loss: 0.035788  [25600/54000]
ep:7/15    loss: 0.019800  [28800/54000]
ep:7/15    loss: 0.087994  [32000/54000]
ep:7/15    loss: 0.191152  [35200/54000]
ep:7/15    loss: 0.074546  [38400/54000]
ep:7/15    loss: 0.157479  [41600/54000]
ep:7/15    loss: 0.040917  [44800/54000]
ep:7/15    loss: 0.073770  [48000/54000]
ep:7/15    loss: 0.277034  [51200/54000]
-----------------------------
Val Acc:0.98  Val loss:0.065641    Train Acc:0.97
Loss decreased 0.093364->0.065641, Saving
ep:8/15    loss: 0.040555  [    0/54000]
ep:8/15    loss: 0.062192  [ 3200/54000]
ep:8/15    loss: 0.016811  [ 6400/54000]
ep:8/15    loss: 0.021586  [ 9600/54000]
ep:8/15    loss: 0.038521  [12800/54000]
ep:8/15    loss: 0.008720  [16000/54000]
ep:8/15    loss: 0.005650  [19200/54000]
ep:8/15    loss: 0.072193  [22400/54000]
ep:8/15    loss: 0.010202  [25600/54000]
ep:8/15    loss: 0.102693  [28800/54000]
ep:8/15    loss: 0.051277  [32000/54000]
ep:8/15    loss: 0.030858  [35200/54000]
ep:8/15    loss: 0.104151  [38400/54000]
ep:8/15    loss: 0.011677  [41600/54000]
ep:8/15    loss: 0.095854  [44800/54000]
ep:8/15    loss: 0.173036  [48000/54000]
ep:8/15    loss: 0.102062  [51200/54000]
-----------------------------
Val Acc:0.98  Val loss:0.074261    Train Acc:0.98
ep:9/15    loss: 0.059443  [    0/54000]
ep:9/15    loss: 0.005752  [ 3200/54000]
ep:9/15    loss: 0.058958  [ 6400/54000]
ep:9/15    loss: 0.011620  [ 9600/54000]
ep:9/15    loss: 0.005258  [12800/54000]
ep:9/15    loss: 0.016916  [16000/54000]
ep:9/15    loss: 0.015311  [19200/54000]
ep:9/15    loss: 0.033372  [22400/54000]
ep:9/15    loss: 0.013802  [25600/54000]
ep:9/15    loss: 0.042138  [28800/54000]
ep:9/15    loss: 0.049595  [32000/54000]
ep:9/15    loss: 0.072809  [35200/54000]
ep:9/15    loss: 0.376627  [38400/54000]
ep:9/15    loss: 0.062718  [41600/54000]
ep:9/15    loss: 0.014629  [44800/54000]
ep:9/15    loss: 0.127586  [48000/54000]
ep:9/15    loss: 0.018414  [51200/54000]
-----------------------------
Val Acc:0.99  Val loss:0.043443    Train Acc:0.98
Loss decreased 0.065641->0.043443, Saving
ep:10/15    loss: 0.005942  [    0/54000]
ep:10/15    loss: 0.008738  [ 3200/54000]
ep:10/15    loss: 0.016822  [ 6400/54000]
ep:10/15    loss: 0.141178  [ 9600/54000]
ep:10/15    loss: 0.031690  [12800/54000]
ep:10/15    loss: 0.092666  [16000/54000]
ep:10/15    loss: 0.001373  [19200/54000]
ep:10/15    loss: 0.017421  [22400/54000]
ep:10/15    loss: 0.001991  [25600/54000]
ep:10/15    loss: 0.035179  [28800/54000]
ep:10/15    loss: 0.003204  [32000/54000]
ep:10/15    loss: 0.003591  [35200/54000]
ep:10/15    loss: 0.023441  [38400/54000]
ep:10/15    loss: 0.004778  [41600/54000]
ep:10/15    loss: 0.130455  [44800/54000]
ep:10/15    loss: 0.019411  [48000/54000]
ep:10/15    loss: 0.055560  [51200/54000]
-----------------------------
Val Acc:0.98  Val loss:0.065867    Train Acc:0.99
ep:11/15    loss: 0.117705  [    0/54000]
ep:11/15    loss: 0.012178  [ 3200/54000]
ep:11/15    loss: 0.004384  [ 6400/54000]
ep:11/15    loss: 0.067308  [ 9600/54000]
ep:11/15    loss: 0.009102  [12800/54000]
ep:11/15    loss: 0.137794  [16000/54000]
ep:11/15    loss: 0.162319  [19200/54000]
ep:11/15    loss: 0.002432  [22400/54000]
ep:11/15    loss: 0.003240  [25600/54000]
ep:11/15    loss: 0.022724  [28800/54000]
ep:11/15    loss: 0.091451  [32000/54000]
ep:11/15    loss: 0.025176  [35200/54000]
ep:11/15    loss: 0.011759  [38400/54000]
ep:11/15    loss: 0.073639  [41600/54000]
ep:11/15    loss: 0.086882  [44800/54000]
ep:11/15    loss: 0.081936  [48000/54000]
ep:11/15    loss: 0.027485  [51200/54000]
-----------------------------
Val Acc:0.99  Val loss:0.050109    Train Acc:0.99
ep:12/15    loss: 0.049656  [    0/54000]
ep:12/15    loss: 0.011203  [ 3200/54000]
ep:12/15    loss: 0.035955  [ 6400/54000]
ep:12/15    loss: 0.001243  [ 9600/54000]
ep:12/15    loss: 0.069378  [12800/54000]
ep:12/15    loss: 0.000088  [16000/54000]
ep:12/15    loss: 0.021276  [19200/54000]
ep:12/15    loss: 0.066492  [22400/54000]
ep:12/15    loss: 0.002369  [25600/54000]
ep:12/15    loss: 0.000581  [28800/54000]
ep:12/15    loss: 0.017431  [32000/54000]
ep:12/15    loss: 0.032545  [35200/54000]
ep:12/15    loss: 0.054851  [38400/54000]
ep:12/15    loss: 0.013917  [41600/54000]
ep:12/15    loss: 0.024587  [44800/54000]
ep:12/15    loss: 0.022845  [48000/54000]
ep:12/15    loss: 0.074194  [51200/54000]
-----------------------------
Val Acc:0.99  Val loss:0.043936    Train Acc:0.99
ep:13/15    loss: 0.000013  [    0/54000]
ep:13/15    loss: 0.000563  [ 3200/54000]
ep:13/15    loss: 0.001436  [ 6400/54000]
ep:13/15    loss: 0.000222  [ 9600/54000]
ep:13/15    loss: 0.001784  [12800/54000]
ep:13/15    loss: 0.076139  [16000/54000]
ep:13/15    loss: 0.000025  [19200/54000]
ep:13/15    loss: 0.002534  [22400/54000]
ep:13/15    loss: 0.173512  [25600/54000]
ep:13/15    loss: 0.056487  [28800/54000]
ep:13/15    loss: 0.024167  [32000/54000]
ep:13/15    loss: 0.001972  [35200/54000]
ep:13/15    loss: 0.000004  [38400/54000]
ep:13/15    loss: 0.000299  [41600/54000]
ep:13/15    loss: 0.070384  [44800/54000]
ep:13/15    loss: 0.007482  [48000/54000]
ep:13/15    loss: 0.002188  [51200/54000]
-----------------------------
Val Acc:0.99  Val loss:0.059131    Train Acc:0.99
ep:14/15    loss: 0.000828  [    0/54000]
ep:14/15    loss: 0.008337  [ 3200/54000]
ep:14/15    loss: 0.001755  [ 6400/54000]
ep:14/15    loss: 0.013461  [ 9600/54000]
ep:14/15    loss: 0.011386  [12800/54000]
ep:14/15    loss: 0.054425  [16000/54000]
ep:14/15    loss: 0.000451  [19200/54000]
ep:14/15    loss: 0.013450  [22400/54000]
ep:14/15    loss: 0.001624  [25600/54000]
ep:14/15    loss: 0.069137  [28800/54000]
ep:14/15    loss: 0.087556  [32000/54000]
ep:14/15    loss: 0.041326  [35200/54000]
ep:14/15    loss: 0.005129  [38400/54000]
ep:14/15    loss: 0.011184  [41600/54000]
ep:14/15    loss: 0.053681  [44800/54000]
ep:14/15    loss: 0.001017  [48000/54000]
ep:14/15    loss: 0.002053  [51200/54000]
-----------------------------
Val Acc:0.99  Val loss:0.062812    Train Acc:0.99
